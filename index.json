[{"categories":null,"content":"sync.Pool","date":"2024-02-06","objectID":"/go-sync_pool/","tags":["golang"],"title":"Golang 性能提升 —— sync.Pool","uri":"/go-sync_pool/"},{"categories":null,"content":" 一句话总结 : 保存和复用临时对象，减少内存分配，降低 GC 压力。 ","date":"2024-02-06","objectID":"/go-sync_pool/:0:0","tags":["golang"],"title":"Golang 性能提升 —— sync.Pool","uri":"/go-sync_pool/"},{"categories":null,"content":"定义 sync.Pool 是 Golang 内置的对象池技术，可用于缓存临时对象，避免因频繁建立临时对象所带来的消耗以及对 GC 造成的压力。 注 : sync.Pool 缓存的对象随时可能被无通知的清除，因此不能将 sync.Pool 用于存储持久对象的场景。 ","date":"2024-02-06","objectID":"/go-sync_pool/:1:0","tags":["golang"],"title":"Golang 性能提升 —— sync.Pool","uri":"/go-sync_pool/"},{"categories":null,"content":"使用 其实，这个数据类型不难，它只提供了三个对外的方法：New、Get 和 Put。 New（Pool struct 包含一个 New 字段，这个字段的类型是函数 func() interface{}。当调用 Pool 的 Get 方法从池中获取元素，没有更多的空闲元素可返回时，就会调用这个 New 方法来创建新的元素。如果你没有设置 New 字段，没有更多的空闲元素可返回时，Get 方法将返回 nil，表明当前没有可用的元素） Get（如果调用这个方法，就会从 Pool取走一个元素，这也就意味着，这个元素会从 Pool 中移除，返回给调用者。不过，除了返回值是正常实例化的元素，Get 方法的返回值还可能会是一个 nil，所以你在使用的时候，可能需要判断） Put（这个方法用于将一个元素返还给 Pool，Pool 会把这个元素保存到池中，并且可以复用。但如果 Put 一个 nil 值，Pool 就会忽略这个值。） ","date":"2024-02-06","objectID":"/go-sync_pool/:2:0","tags":["golang"],"title":"Golang 性能提升 —— sync.Pool","uri":"/go-sync_pool/"},{"categories":null,"content":"示例 package main import ( \"fmt\" \"sync\" ) var pool *sync.Pool type Person struct { Name string } func initPool() { pool = \u0026sync.Pool { New: func()interface{} { // 实现 New 函数。对象池中没有对象时，将会调用 New 函数创建。 return new(Person) }, } } func main() { initPool() p := pool.Get().(*Person) // Get() 用于从对象池中获取对象，因为返回值是 interface{}，因此需要类型转换。 fmt.Println(\"首次从 pool 里获取：\", p) p.Name = \"first\" fmt.Printf(\"设置 p.Name = %s\\n\", p.Name) pool.Put(p) // Put() 则是在对象使用完毕后，返回对象池。 fmt.Println(\"Pool 里已有一个对象：\u0026{first}，调用 Get: \", pool.Get().(*Person)) fmt.Println(\"Pool 没有对象了，调用 Get: \", pool.Get().(*Person)) } ","date":"2024-02-06","objectID":"/go-sync_pool/:3:0","tags":["golang"],"title":"Golang 性能提升 —— sync.Pool","uri":"/go-sync_pool/"},{"categories":null,"content":"场景 高并发场景 : 一个对象会被大量创建 稳定创建对象场景 : 不是一次性，也不是间隔很久才创建一次 ","date":"2024-02-06","objectID":"/go-sync_pool/:4:0","tags":["golang"],"title":"Golang 性能提升 —— sync.Pool","uri":"/go-sync_pool/"},{"categories":null,"content":"参考 https://marksuper.xyz/2021/09/02/sync_pool/ https://geektutu.com/post/hpg-sync-pool.html ","date":"2024-02-06","objectID":"/go-sync_pool/:5:0","tags":["golang"],"title":"Golang 性能提升 —— sync.Pool","uri":"/go-sync_pool/"},{"categories":null,"content":"TCP报文类型","date":"2024-01-28","objectID":"/network-tcp_type/","tags":["network"],"title":"计算机网络 —— TCP报文类型","uri":"/network-tcp_type/"},{"categories":null,"content":" 很多人可能知道TCP报文格式，但当提及报文类型时却一问三不知。 本文梳理了TCP报文类型，希望对您有帮助 ~ TCP的报文类型是由标志位(code bits)决定的，所以TCP报文类型一共6种。 在TCP层，有个FLAGS字段，这个字段有以下几个标识：SYN(synchronous建立联机)，ACK(acknowledgement 确认)，PSH(push传送)，FIN(finish结束)，RST(reset重置)，URG(urgent紧急)。它们的含义分别是 : SYN : 建立连接 FIN : 关闭连接 ACK : 响应连接 PSH : 数据传输(只出现在DATA内容不为0的包中) RST : 重置连接(解决TCP异常连接不释放的机制) URG : 紧急发送(此报文段中有紧急数据，应尽快传送) 参考 https://www.cnblogs.com/linguoguo/p/15631417.html https://juejin.cn/s/tcp%20%E6%8A%A5%E6%96%87%E7%B1%BB%E5%9E%8B https://acptek.github.io/2020/07/10/TCP-IP-%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E6%8A%A5%E6%96%87%E5%8D%8F%E8%AE%AE/ https://blog.csdn.net/qq_35420908/article/details/72459105 ","date":"2024-01-28","objectID":"/network-tcp_type/:0:0","tags":["network"],"title":"计算机网络 —— TCP报文类型","uri":"/network-tcp_type/"},{"categories":null,"content":"容灾架构","date":"2024-01-02","objectID":"/distributed/","tags":["Distributed"],"title":"分布式系统 —— 容灾架构","uri":"/distributed/"},{"categories":null,"content":" 后台服务可以分为两类 : 有状态和无状态。 容灾架构对无状态的服务(计算型服务)很简单，不外乎就是多加相同实例；但对有状态服务(存储型服务)就不是那么轻松。 下文为作者梳理的容灾架构相关内容，希望对您有帮助 ~ ","date":"2024-01-02","objectID":"/distributed/:0:0","tags":["Distributed"],"title":"分布式系统 —— 容灾架构","uri":"/distributed/"},{"categories":null,"content":"一、术语介绍 说明： 在下文中，机房、数据中心、IDC是同义词(统一用机房) 在下文中，数据库不仅仅指关系型数据库，还可能是其他类型的数据库 术语 解释 冷备 (需要停机)通过停止数据库对外服务的能力，定时将主数据中心的数据库文件备份到其他数据中心。当丢失数据时，可以通过冷备回复数据，以保证数据安全。 双机热备 (无需停机)通过数据库主从负载或binlog订阅等技术对主数据中心进行实时备份。热备提供实时服务，当主数据中心不可用时，热备可以自动接管业务，保证业务不间断运行，用户端对主备切换无感知 同城多活 同城的数据中心之间物理距离比较近，并且使用专线连接，虽然跨数据中心的访问延迟比单个数据中心内部大，但可接受 异地多活 异地的数据中心之间物理距离较远，网速延迟是不可忽视的因素。比如北京到上海的距离是1300公里，即便架设专线，光纤以光速传输，一个唠会也要10ms。线路之间还有路由器、交换机等设备，实际延迟可达 30ms ~ 100ms，如果网络抖动，延迟可能达到 1s 解释： “活\"是指实时提供服务的意思；与\"活\"对应的是字是\"备”，备是备份，正常情况下对外是不提供服务的。 ","date":"2024-01-02","objectID":"/distributed/:1:0","tags":["Distributed"],"title":"分布式系统 —— 容灾架构","uri":"/distributed/"},{"categories":null,"content":"二、故障分类 类别 出现原因 概率 影响面 主机故障 主机硬件故障、网络故障、负载过高等 大 小 机房故障 机房网络故障、店里故障、制冷系统故障、自然灾害等。比如塘沽爆炸事件 小 大 地域故障 战争、强自然灾害等。比如河南水灾 极小 极大 ","date":"2024-01-02","objectID":"/distributed/:2:0","tags":["Distributed"],"title":"分布式系统 —— 容灾架构","uri":"/distributed/"},{"categories":null,"content":"三、同城多活 ","date":"2024-01-02","objectID":"/distributed/:3:0","tags":["Distributed"],"title":"分布式系统 —— 容灾架构","uri":"/distributed/"},{"categories":null,"content":"同城双活 同城多活主要是同城双活，架构图如下 ","date":"2024-01-02","objectID":"/distributed/:3:1","tags":["Distributed"],"title":"分布式系统 —— 容灾架构","uri":"/distributed/"},{"categories":null,"content":"四、两地三中心(GDPS) 两地三中心通常指的是 “同城双活，异地备份”。 ","date":"2024-01-02","objectID":"/distributed/:4:0","tags":["Distributed"],"title":"分布式系统 —— 容灾架构","uri":"/distributed/"},{"categories":null,"content":"两地 两地 ——— 同城、异地 ","date":"2024-01-02","objectID":"/distributed/:4:1","tags":["Distributed"],"title":"分布式系统 —— 容灾架构","uri":"/distributed/"},{"categories":null,"content":"三中心 三中心 ——— 生产中心、同城容灾中心、异地容灾中心 ","date":"2024-01-02","objectID":"/distributed/:4:2","tags":["Distributed"],"title":"分布式系统 —— 容灾架构","uri":"/distributed/"},{"categories":null,"content":"五、伪异地多活 ","date":"2024-01-02","objectID":"/distributed/:5:0","tags":["Distributed"],"title":"分布式系统 —— 容灾架构","uri":"/distributed/"},{"categories":null,"content":"六、异地双活 ","date":"2024-01-02","objectID":"/distributed/:6:0","tags":["Distributed"],"title":"分布式系统 —— 容灾架构","uri":"/distributed/"},{"categories":null,"content":"七、异地多活 ","date":"2024-01-02","objectID":"/distributed/:7:0","tags":["Distributed"],"title":"分布式系统 —— 容灾架构","uri":"/distributed/"},{"categories":null,"content":"八、单元化 ","date":"2024-01-02","objectID":"/distributed/:8:0","tags":["Distributed"],"title":"分布式系统 —— 容灾架构","uri":"/distributed/"},{"categories":null,"content":"九、数据库架构 参考 https://cloud.tencent.com/developer/article/1696857 https://blog.51cto.com/u_15233911/2872723 http://timd.cn/distributed-system-disaster-recovery-architecture/ https://www.bilibili.com/video/BV18v411c7FX/?spm_id_from=333.337.search-card.all.click\u0026vd_source=984bb0162787242633addc56b07edfb8 ","date":"2024-01-02","objectID":"/distributed/:9:0","tags":["Distributed"],"title":"分布式系统 —— 容灾架构","uri":"/distributed/"},{"categories":null,"content":"逃逸分析","date":"2023-12-25","objectID":"/go-escape_analyze/","tags":["golang"],"title":"Golang 底层原理 —— 逃逸分析","uri":"/go-escape_analyze/"},{"categories":null,"content":" 逃逸分析 —— 让Golang程序员专注高效工作的挖井人！ 对于手动管理内存的语言，比如 C/C++，调用著名的malloc和new函数可以在堆上分配一块内存，这块内存的使用和释放由程序员决定。一不小心，就会发生内存泄露的问题。 但是 Golang 不一样，虽然 Golang 语言里也有 new关键字。Golang 编译器决定了变量应该分配到什么地方时会进行逃逸分析。使用new函数得到的内存不一定就在堆上。堆和栈的区别对程序员“模糊化”了，这一切都是Go编译器在背后帮我们完成的。一个变量是在堆上分配，还是在栈上分配，是经过编译器的逃逸分析之后得出的结论。 int *foo ( void ) { int t = 3; return \u0026t; } 这段C代码的\u0026t是个野指针，可能会导致大问题！因为指针超出了作用域。解决方法：可以使用new来创建对象，分配在堆上， 然后delete。 但这段代码在Golang中可以正常运行，这是因为golang会在编译期间进行逃逸分析，将变量创建在合适的地方（堆或者栈）。 一、什么是逃逸分析? 官方定义 : 在编译原理中，分析指针动态范围的方法称之为逃逸分析。 个人理解 : Golang在代码编译过程中对所有变量进行内存分配的分析过程，用于判断变量的内存分配到栈还是堆上。 二、为什么要逃逸分析? 前面讲的C/C++中出现的问题，在Go中作为一个语言特性被大力推崇。真是C/C++之砒霜Go之蜜糖！ C/C++中动态分配的内存需要我们手动释放，导致猿们平时在写程序时，如履薄冰。这样做有他的好处：程序员可以完全掌控内存。但是缺点也是很多的：经常出现忘记释放内存，导致内存泄露。所以，很多现代语言都加上了垃圾回收机制。 Go的垃圾回收，让堆和栈对程序员保持透明。真正解放了程序员的双手，让他们可以专注于业务，“高效”地完成代码编写。把那些内存管理的复杂机制交给编译器，而程序员可以去享受生活。 逃逸分析这种“骚操作”把变量合理地分配到它该去的地方，“找准自己的位置”。即使你是用new申请到的内存，如果我发现你竟然在退出函数后没有用了，那么就把你丢到栈上，毕竟栈上的内存分配比堆上快很多；反之，即使你表面上只是一个普通的变量，但是经过逃逸分析后发现在退出函数之后还有其他地方在引用，那我就把你分配到堆上。真正地做到“按需分配”，提前实现共产主义！ 如果变量都分配到堆上，堆不像栈可以自动清理。它会引起Go频繁地进行垃圾回收，而垃圾回收会占用比较大的系统开销（占用CPU容量的25%）。 堆和栈相比，堆适合不可预知大小的内存分配。但是为此付出的代价是分配速度较慢，而且会形成内存碎片。栈内存分配则会非常快。栈分配内存只需要两个CPU指令：“PUSH”和“RELEASE”，分配和释放；而堆分配内存首先需要去找到一块大小合适的内存块，之后要通过垃圾回收才能释放。 通过逃逸分析**，可以尽量把那些不需要分配到堆上的变量直接分配到栈上，堆上的变量少了，会减轻分配堆内存的开销，同时也会减少gc的压力，提高程序的运行速度。** 三、逃逸分析如何完成 Go逃逸分析最基本的原则是：如果一个函数返回对一个变量的引用，那么它就会发生逃逸。 简单来说，编译器会分析代码的特征和代码生命周期，Go中的变量只有在编译器可以证明在函数返回后不会再被引用的，才分配到栈上，其他情况下都是分配到堆上。 Go语言里没有一个关键字或者函数可以直接让变量被编译器分配到堆上，相反，编译器通过分析代码来决定将变量分配到何处。 对一个变量取地址，可能会被分配到堆上。但是编译器进行逃逸分析后，如果考察到在函数返回后，此变量不会被引用，那么还是会被分配到栈上。 简单来说，编译器会根据变量是否被外部引用来决定是否逃逸： 1）如果函数外部没有引用，则优先放到栈中； 2） 如果函数外部存在引用，则必定放到堆中； 针对第一条，也可能放到堆上的情形：定义了一个很大的数组，需要申请的内存过大，超过了栈的存储能力。 四、总结 1、堆上动态分配内存比栈上静态分配内存，开销大很多。 2、变量分配在栈上需要能在编译期确定它的作用域，否则会分配到堆上。 3、Go编译器会在编译期对考察变量的作用域，并作一系列检查，如果它的作用域在运行期间对编译器一直是可知的，那么就会分配到栈上。简单来说，编译器会根据变量是否被外部引用来决定是否逃逸。 4、对于Go程序员来说，编译器的这些逃逸分析规则不需要掌握，我们只需通过go build -gcflags ‘-m’命令来观察变量逃逸情况就行了。 5、不要盲目使用变量的指针作为函数参数，虽然它会减少复制操作。但其实当参数为变量自身的时候，复制是在栈上完成的操作，开销远比变量逃逸后动态地在堆上分配内存少的多。 6、逃逸分析在编译阶段完成的。 参考 https://www.jianshu.com/p/ad9dbc81a0aa ","date":"2023-12-25","objectID":"/go-escape_analyze/:0:0","tags":["golang"],"title":"Golang 底层原理 —— 逃逸分析","uri":"/go-escape_analyze/"},{"categories":null,"content":"主从复制、哨兵模式、集群模式","date":"2023-11-16","objectID":"/redis-high_availability/","tags":["redis"],"title":"Redis 高可用 —— 主从、哨兵、集群","uri":"/redis-high_availability/"},{"categories":null,"content":" 所谓的高可用，也叫 HA（High Availability），是分布式系统架构设计中必须考虑的因素之一，它通常指，通过设计减少系统不能提供服务的时间。 本文梳理了Redis高可用的三种模式(主从、哨兵、集群)。希望对您有帮助 ~ ","date":"2023-11-16","objectID":"/redis-high_availability/:0:0","tags":["redis"],"title":"Redis 高可用 —— 主从、哨兵、集群","uri":"/redis-high_availability/"},{"categories":null,"content":"主从模式 ","date":"2023-11-16","objectID":"/redis-high_availability/:1:0","tags":["redis"],"title":"Redis 高可用 —— 主从、哨兵、集群","uri":"/redis-high_availability/"},{"categories":null,"content":"主从复制怎么实现的 主从复制采用三种方式(全量同步、命令传播、增量同步)配合实现。 主从服务器第一次同步的时候，采用全量复制，此时主服务器最耗时的两个地方(生成RDB文件、传输RDB文件)。为了避免过多的从服务器和主服务器进行全量复制，可以把一部分从服务器设置成「经理角色」，让它也有自己的从服务器，分摊主服务器的压力。 第一次同步完成后，主从服务器都会维护一个长连接，主服务器在接收到写操作命令后，会通过这个连接将写命令传播给从服务器，来保证主从服务器的数据一致性。 如果遇到网络断开，增量复制就起到了作用。只不过增量复制和repl_backlog_size有关。 全量同步(第一次同步) 全量同步分为三个阶段 第一阶段 : 建立链接、协商同步 第二阶段 : 主服务器同步数据给从服务器 第三阶段 : 主服务器会将 replication buffer 缓冲区新写操作命令发送给从服务器 注 : psync 命令包含两个参数，分别是主服务器的 runID 和复制进度 offset。 基于长连接的命令传播 主从服务器在完成第一次同步后，双方之间就会维护一个 TCP 连接。 增量复制 ","date":"2023-11-16","objectID":"/redis-high_availability/:1:1","tags":["redis"],"title":"Redis 高可用 —— 主从、哨兵、集群","uri":"/redis-high_availability/"},{"categories":null,"content":"哨兵模式 ","date":"2023-11-16","objectID":"/redis-high_availability/:2:0","tags":["redis"],"title":"Redis 高可用 —— 主从、哨兵、集群","uri":"/redis-high_availability/"},{"categories":null,"content":"集群模式 参考 https://cloud.tencent.com/developer/article/1924661 https://www.xiaolincoding.com/redis/cluster/cache_problem.html#%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9 ","date":"2023-11-16","objectID":"/redis-high_availability/:3:0","tags":["redis"],"title":"Redis 高可用 —— 主从、哨兵、集群","uri":"/redis-high_availability/"},{"categories":null,"content":"内存管理","date":"2023-10-05","objectID":"/go-memory_manage/","tags":["golang"],"title":"Golang 底层原理 —— 内存管理","uri":"/go-memory_manage/"},{"categories":null,"content":" 作者当前认知的Golang内存管理机制 核心设计思想 多级内存分配模块 : 减少内存分配时锁的使用与系统调用 多尺度内存单元 : 减少内存分配产生的碎片 内存管理分类 栈内存管理 : 栈上内存由编译器管理 堆内存管理 : 堆上内存由程序管理 注 : 至于一个变量分配在堆上还是栈上，与语法无关，主要依靠golang的逃逸分析 ","date":"2023-10-05","objectID":"/go-memory_manage/:0:0","tags":["golang"],"title":"Golang 底层原理 —— 内存管理","uri":"/go-memory_manage/"},{"categories":null,"content":"两者对比 栈与堆相比劣势 栈空间较小(8M或10M)，不适合存放空间占用大的对象 函数内的局部变量离开函数体会被自动弹出栈，离开函数作用域依然存活的指针也不适合栈存放 栈与堆相比优势 管理简单(由编译器完成) 分配和释放速度快(无垃圾回收过程) 栈上内存有很好的局部性(堆上2块数据可能分部在不同的页上) 本文重点 : 堆内存管理 Golang堆内存分配器借鉴了TCMalloc现代分配器的设计思想 一次性或者提前分配多级内存模块(减少内存分配时锁的使用和调用操作系统分配内存的开销) 多尺度内存单元(减少内存分配产生的碎片) mspan是堆上内存管理的基本单元，由一连串的页构成(8KB)。Golang根据内存大小将mspan分成67个等级，每个mspan被切分成了很多小对象，用于不同尺度的对象分配。 每个线程有一个独立的堆内存mcache，在mcache上申请内存不需要加锁，每个mache有67种尺度内存单元，每个尺度的内存又由mspan构成，分别存储指针类型和非指针类型。当程序在堆上创建对象时，分配器会根据对象的大小(小于32KB)和类型(是否为指针)从67*2中mspan中分配内存。 如果mcache内存不足，会从所有线程共享的缓存mcentral中申请内存。一共有672中mcentral，mcache中空间不足的mspan会从对应的mcentral申请内存，申请内存时需要加锁，但是加锁的概率变成了1/(672)，申请效率很高。为了进一步提升内存分配效率，每一个mcentral由2个链表构成，一个存放已经分配给mcache的mspan，一个存放未被占用或者已经被mcache释放的mspan。 当mcentral上mspan不足时或者对象大于32KB时会从mheap上申请内存，全局仅有一个mheap，访问时也需要加锁。mheap中有2棵二叉排序树 : free，scav；free存放的是空闲非垃圾回收的mspan，scav存放的是空闲已垃圾回收的mspan。内存分配时会优先从free中搜索可用的span，如果没找到会从scav中搜索可用的span，如果还没找到，会向操作系统申请内存，在重新搜索2棵二叉树，必然能找到可用的span。从操作系统申请的内存也会保存到span中，然后加入free树中。 参考 https://www.jianshu.com/p/5641648664d8 ","date":"2023-10-05","objectID":"/go-memory_manage/:0:1","tags":["golang"],"title":"Golang 底层原理 —— 内存管理","uri":"/go-memory_manage/"},{"categories":null,"content":"缓存雪崩、击穿、穿透","date":"2023-09-08","objectID":"/redis-cache_exception/","tags":["redis"],"title":"Redis 缓存异常 —— 缓存雪崩、击穿、穿透","uri":"/redis-cache_exception/"},{"categories":null,"content":" 引入缓存层，会有缓存异常的三个常见问题，分别是缓存雪崩、击穿、穿透。 本文总结了这三个问题的定义、原因以及应对方案。 请看如下表格，希望对您有帮助 ~ 缓存异常问题描述产生原因应对方案 缓存雪崩大量的应用请求无法在Redis缓存中进行处理，从而使得大量请求发送到数据库层，导致数据库压力过大甚至宕机。大量数据同时过期- 均匀设置过期时间，避免同一时间过期- 互斥锁，保证同一时间只有一个应用在构建缓存- 双key策略，主key设置过期时间，备key永久，主key过期时，返回备key的内容- 后台定时刷新 Redis故障宕机- 服务熔断- 请求限流- 搭建Redis高可用集群 缓存击穿一个热点数据的缓存失效，导致大量请求直接落到数据库上，造成数据库压力过大，影响系统性能。频繁访问的热点数据过期- 互斥锁- 不给热点数据设置过期时间- 后台定时刷新(过期前刷新) 缓存穿透被大量请求缓存和数据库都没有的数据，所有的请求都会直接穿透到数据库，会导致数据库压力过大，甚至垮掉。访问的数据既不在缓存，也不再数据库- 非法请求限制- 缓存空值- 布隆过滤器 参考 https://cloud.tencent.com/developer/article/1924661 https://www.xiaolincoding.com/redis/cluster/cache_problem.html#%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9 ","date":"2023-09-08","objectID":"/redis-cache_exception/:0:0","tags":["redis"],"title":"Redis 缓存异常 —— 缓存雪崩、击穿、穿透","uri":"/redis-cache_exception/"},{"categories":null,"content":"索引失效","date":"2023-08-17","objectID":"/mysql-index_failure/","tags":["mysql"],"title":"MySQL 优化手段 —— 索引失效","uri":"/mysql-index_failure/"},{"categories":null,"content":" 聊聊索引失效 总结 模 : 模糊查询。like查询以%开头，会导致索引失效。可以有两种方式优化(覆盖索引、最左匹配) 数 : 数据类型。编写SQL时要保证索引字段与匹配数据类型一致。 函 : 数据处理。索引字段不做函数处理。 空 : null值。唯一索引有null值。 运 : 运算。索引字段不做运算。 左 : 最左匹配原则。 回 : 回表超过临界值，避免回表尽量覆盖索引。 参考 https://bbs.huaweicloud.com/blogs/333163 ","date":"2023-08-17","objectID":"/mysql-index_failure/:0:0","tags":["mysql"],"title":"MySQL 优化手段 —— 索引失效","uri":"/mysql-index_failure/"},{"categories":null,"content":"浏览器访问网页的全过程","date":"2023-07-13","objectID":"/whole_process_of_accessing_web_pages/","tags":["Fundamentals_Of_Computer"],"title":"计算机基础 —— 浏览器访问网页过程及后续","uri":"/whole_process_of_accessing_web_pages/"},{"categories":null,"content":" 在浏览器地址栏输入URL，按下回车后究竟发生了什么？ 本文还展示了研发人员是如何构建发布用户获取到的Web资源？ 该部分为作者梳理的精简内容，希望对您有帮助 ~ 浏览器访问网页的全过程 ","date":"2023-07-13","objectID":"/whole_process_of_accessing_web_pages/:0:0","tags":["Fundamentals_Of_Computer"],"title":"计算机基础 —— 浏览器访问网页过程及后续","uri":"/whole_process_of_accessing_web_pages/"},{"categories":null,"content":"第一步：浏览器输入域名 例如输入：www.baidu.com ","date":"2023-07-13","objectID":"/whole_process_of_accessing_web_pages/:1:0","tags":["Fundamentals_Of_Computer"],"title":"计算机基础 —— 浏览器访问网页过程及后续","uri":"/whole_process_of_accessing_web_pages/"},{"categories":null,"content":"第二步：浏览器查找域名的IP地址 浏览器会把输入的域名解析成对应的IP，其过程如下： 查找浏览器缓存：因为浏览器一般会缓存DNS记录一段时间，不同浏览器的时间可能不一样，一般2-30分钟不等，浏览器去查找这些缓存，如果有缓存，直接返回IP，否则下一步。 查找系统缓存：浏览器缓存中找不到IP之后，浏览器会进行系统调用（windows中是gethostbyname），查找本机的hosts文件，如果找到，直接返回IP，否则下一步。 查找路由器缓存：如果1,2步都查询无果，则需要借助网络，路由器一般都有自己的DNS缓存，将前面的请求发给路由器，查找ISP 服务商缓存 DNS的服务器，如果查找到IP则直接返回，没有的话继续查找。 递归查询：如果以上步骤还找不到，则ISP的DNS服务器就会进行递归查询，所谓递归查询就是如果主机所询问的本地域名服务器不知道被查询域名的IP地址，那么本地域名服务器就以DNS客户的身份，向其他根域名服务器继续发出查询请求报文，而不是让该主机自己进行下一步查询。（本地域名服务器地址是通过DHPC协议获取地址，DHPC是负责分配IP地址的） 迭代查询：本地域名服务器采用迭代查询，它先向一个根域名服务器查询。本地域名服务器向根域名服务器的查询一般都是采用迭代查询。所谓迭代查询就是当根域名服务器收到本地域名服务器发出的查询请求报文后，要么告诉本地域名服务器下一步应该查询哪一个域名服务器，然后本地域名服务器自己进行后续的查询。（而不是替代本地域名服务器进行后续查询）。 本例子中：根域名服务器告诉本地域名服务器，下一次应查询的顶级域名服务器dns.com的IP地址。本地域名服务器向顶级域名服务器dns.com进行查询。顶级域名服务器dns.com告诉本地域名服务器，下一次应查询的权限域名服务器www.baidu.com的IP地址。本地域名服务器向权限域名服务器dns.baidu.com进行查询。权限域名服务器www.baidu.com告诉本地域名服务器，所查询的主机www.baidu.com的IP地址。本地域名服务器最后把结果告诉主机。 ","date":"2023-07-13","objectID":"/whole_process_of_accessing_web_pages/:2:0","tags":["Fundamentals_Of_Computer"],"title":"计算机基础 —— 浏览器访问网页过程及后续","uri":"/whole_process_of_accessing_web_pages/"},{"categories":null,"content":"第三步 ：浏览器与目标服务器建立TCP连接 主机浏览器通过DNS解析得到了目标服务器的IP地址后，与服务器建立TCP连接。 TCP3次握手连接：浏览器所在的客户机向服务器发出连接请求报文（SYN标志为1）；服务器接收报文后，同意建立连接，向客户机发出确认报文（SYN，ACK标志位均为1）；客户机接收到确认报文后，再次向服务器发出报文，确认已接收到确认报文；此处客户机与服务器之间的TCP连接建立完成，开始通信。 ","date":"2023-07-13","objectID":"/whole_process_of_accessing_web_pages/:3:0","tags":["Fundamentals_Of_Computer"],"title":"计算机基础 —— 浏览器访问网页过程及后续","uri":"/whole_process_of_accessing_web_pages/"},{"categories":null,"content":"第四步：浏览器通过http协议发送请求 浏览器向主机发起一个HTTP-GET方法报文请求。请求中包含访问的URL，也就是http://www.baidu.com/ ，KeepAlive，长连接，还有User-Agent用户浏览器操作系统信息，编码等。值得一提的是Accep-Encoding和Cookies项。Accept-Encoding一般采用gzip，压缩之后传输html文件。Cookies如果是首次访问，会提示服务器建立用户缓存信息，如果不是，可以利用Cookies对应键值，找到相应缓存，缓存里面存放着用户名，密码和一些用户设置项。 ","date":"2023-07-13","objectID":"/whole_process_of_accessing_web_pages/:4:0","tags":["Fundamentals_Of_Computer"],"title":"计算机基础 —— 浏览器访问网页过程及后续","uri":"/whole_process_of_accessing_web_pages/"},{"categories":null,"content":"第五步：某些服务会做永久重定向响应 对于大型网站存在多个主机站点，了负载均衡或者导入流量，提高SEO排名，往往不会直接返回请求页面，而是重定向。返回的状态码就不是200OK，而是301,302以3开头的重定向码，浏览器在获取了重定向响应后，在响应报文中Location项找到重定向地址，浏览器重新第一步访问即可。 重定向的作用：重定向是为了负载均衡或者导入流量，提高SEO排名。利用一个前端服务器接受请求，然后负载到不同的主机上，可以大大提高站点的业务并发处理能力；重定向也可将多个域名的访问，集中到一个站点；由于baidu.com，www.baidu.com会被搜索引擎认为是两个网站，照成每个的链接数都会减少从而降低排名，永久重定向会将两个地址关联起来，搜索引擎会认为是同一个网站，从而提高排名。 ","date":"2023-07-13","objectID":"/whole_process_of_accessing_web_pages/:5:0","tags":["Fundamentals_Of_Computer"],"title":"计算机基础 —— 浏览器访问网页过程及后续","uri":"/whole_process_of_accessing_web_pages/"},{"categories":null,"content":"第六步：浏览器跟踪重定向地址 当浏览器知道了重定向后最终的访问地址之后，重新发送一个http请求，发送内容同上。 ","date":"2023-07-13","objectID":"/whole_process_of_accessing_web_pages/:6:0","tags":["Fundamentals_Of_Computer"],"title":"计算机基础 —— 浏览器访问网页过程及后续","uri":"/whole_process_of_accessing_web_pages/"},{"categories":null,"content":"第七步：服务器处理请求 服务器接收到获取请求，然后处理并返回一个响应。 ","date":"2023-07-13","objectID":"/whole_process_of_accessing_web_pages/:7:0","tags":["Fundamentals_Of_Computer"],"title":"计算机基础 —— 浏览器访问网页过程及后续","uri":"/whole_process_of_accessing_web_pages/"},{"categories":null,"content":"第八步：服务器发出一个HTML响应 返回状态码200 OK，表示服务器可以响应请求，返回报文，由于在报头中Content-type为“text/html”，浏览器以HTML形式呈现，而不是下载文件。 ","date":"2023-07-13","objectID":"/whole_process_of_accessing_web_pages/:8:0","tags":["Fundamentals_Of_Computer"],"title":"计算机基础 —— 浏览器访问网页过程及后续","uri":"/whole_process_of_accessing_web_pages/"},{"categories":null,"content":"第九步：释放TCP连接 浏览器所在主机向服务器发出连接释放报文，然后停止发送数据； 服务器接收到释放报文后发出确认报文，然后将服务器上未传送完的数据发送完； 服务器数据传输完毕后，向客户机发送连接释放报文； 客户机接收到报文后，发出确认，然后等待一段时间后，释放TCP连接； ","date":"2023-07-13","objectID":"/whole_process_of_accessing_web_pages/:9:0","tags":["Fundamentals_Of_Computer"],"title":"计算机基础 —— 浏览器访问网页过程及后续","uri":"/whole_process_of_accessing_web_pages/"},{"categories":null,"content":"第十步：浏览器显示页面 在浏览器没有完整接受全部HTML文档时，它就已经开始显示这个页面了，浏览器接收到返回的数据包，根据浏览器的渲染机制对相应的数据进行渲染。渲染后的数据，进行相应的页面呈现和脚步的交互。 ","date":"2023-07-13","objectID":"/whole_process_of_accessing_web_pages/:10:0","tags":["Fundamentals_Of_Computer"],"title":"计算机基础 —— 浏览器访问网页过程及后续","uri":"/whole_process_of_accessing_web_pages/"},{"categories":null,"content":"第十一步：浏览器发送获取嵌入在HTML中的其他内容 比如一些样式文件，图片url，js文件url等，浏览器会通过这些url重新发送请求，请求过程依然是HTML读取类似的过程，查询域名，发送请求，重定向等。不过这些静态文件是可以缓存到浏览器中的，有时访问这些文件不需要通过服务器，直接从缓存中取。某些网站也会使用第三方CDN进行托管这些静态文件。 后续 ","date":"2023-07-13","objectID":"/whole_process_of_accessing_web_pages/:11:0","tags":["Fundamentals_Of_Computer"],"title":"计算机基础 —— 浏览器访问网页过程及后续","uri":"/whole_process_of_accessing_web_pages/"},{"categories":null,"content":"研发视角 ","date":"2023-07-13","objectID":"/whole_process_of_accessing_web_pages/:12:0","tags":["Fundamentals_Of_Computer"],"title":"计算机基础 —— 浏览器访问网页过程及后续","uri":"/whole_process_of_accessing_web_pages/"},{"categories":null,"content":"可观测行 ","date":"2023-07-13","objectID":"/whole_process_of_accessing_web_pages/:12:1","tags":["Fundamentals_Of_Computer"],"title":"计算机基础 —— 浏览器访问网页过程及后续","uri":"/whole_process_of_accessing_web_pages/"},{"categories":null,"content":"构建发布 参考 https://blog.csdn.net/jiao_0509/article/details/82491299 ","date":"2023-07-13","objectID":"/whole_process_of_accessing_web_pages/:12:2","tags":["Fundamentals_Of_Computer"],"title":"计算机基础 —— 浏览器访问网页过程及后续","uri":"/whole_process_of_accessing_web_pages/"},{"categories":null,"content":"分库分表","date":"2023-06-30","objectID":"/mysql-separate_librarytable/","tags":["mysql"],"title":"MySQL 优化手段 —— 分库分表","uri":"/mysql-separate_librarytable/"},{"categories":null,"content":" 分库分表 切分目的 当单表的数据量达到1000W或100G以后，优化索引、添加从库等可能对数据库性能提升效果不明显，此时就要考虑对其进行切分了。切分的目的是为了减少数据库的负担，缩短查询的时间。 ","date":"2023-06-30","objectID":"/mysql-separate_librarytable/:0:0","tags":["mysql"],"title":"MySQL 优化手段 —— 分库分表","uri":"/mysql-separate_librarytable/"},{"categories":null,"content":"表垂直拆分 优点：列数据变小，数据页可以存放更多数据，在查询时减少I/O次数 缺点：主键冗余、连表操作（JOIN）、行数据大 ","date":"2023-06-30","objectID":"/mysql-separate_librarytable/:0:1","tags":["mysql"],"title":"MySQL 优化手段 —— 分库分表","uri":"/mysql-separate_librarytable/"},{"categories":null,"content":"表水平拆分 优点：行数据变小；切分出的表结构相同，程序改动小 缺点：连表操作（JOIN）、分片事务一致性难以解决 参考 https://zhuanlan.zhihu.com/p/375951738 ","date":"2023-06-30","objectID":"/mysql-separate_librarytable/:0:2","tags":["mysql"],"title":"MySQL 优化手段 —— 分库分表","uri":"/mysql-separate_librarytable/"},{"categories":null,"content":"浅谈Context","date":"2023-05-22","objectID":"/go-context/","tags":["golang"],"title":"Golang 基本语法 —— 浅谈 Context","uri":"/go-context/"},{"categories":null,"content":" context为Go中的一个标准库, 专门用来处理多个协程之间的控制问题, 比如协程的取消, 协程运行截止时间, 协程运行的超时时间, 协程之间的数据传输等。 context使用规则 context要作为函数的第一个参数使用, 不要试图将它放入结构体中 当方法或函数需要一个context时, 不要传入nil, 可以传入context.TODO context可以传入到不同的协程中,** 并且在多个协程中是安全的** 当context传入到子协程中时, 需要在子协程中监控conext.Done()返回的通道, 当收到通知时, 停止当前子协程的运行, 释放资源并返回到上层 并发安全？ func main() { ctx := context.WithValue(context.Background(), \"asong\", \"test01\") go func() { for { _ = context.WithValue(ctx, \"asong\", \"test02\") } }() go func() { for { _ = context.WithValue(ctx, \"asong\", \"test03\") } }() go func() { for { fmt.Println(ctx.Value(\"asong\")) } }() go func() { for { fmt.Println(ctx.Value(\"asong\")) } }() time.Sleep(10 * time.Second) } context添加的键值对一个链式的，会不断衍生新的context，所以context本身是不可变的**，因此是线程安全的。** !https://secure2.wostatic.cn/static/uSBmnegpS63aHSVxPCKCkq/image.png?auth_key=1709437657-jBqxaGan91qXdknbrRbeKZ-0-fb5050a3090ee6e8b1e7750c44241b3c ","date":"2023-05-22","objectID":"/go-context/:0:0","tags":["golang"],"title":"Golang 基本语法 —— 浅谈 Context","uri":"/go-context/"},{"categories":null,"content":"Context包 父子关系 控制是从上至下的，查找是从下至上的。 context 的实例之间存在父子关系： 当父亲取消或者超时，所有派生的子context 都被取消或者超时 找 key 的时候，子 context 先看自己有没有，没有则去祖先里面找控制是从上至下的，查找是从下至上的。 父context是无法拿到子context的key的值得，只能看到自己的 context.WithCancel的使用 withcancel 使用demo，我理解就是当前线程用来控制子协程退出的工具 package main import ( \"context\" \"fmt\" \"time\" ) func slowfunc1(ctx context.Context) { defer func() { fmt.Println(\"end slowfunc1\") }() fmt.Println(\"start slowfunc1\") for { select { case \u003c-ctx.Done(): fmt.Println(\"slowfunc1 end by main\") return default: } } } func slowfunc(ctx context.Context) { defer func() { fmt.Println(\"end slowfunc\") }() fmt.Println(\"start slowfunc\") go slowfunc1(ctx) for { select { case \u003c-ctx.Done(): fmt.Println(\"slowfunc end by main\") return default: } } } func main() { fmt.Println(\"start main \") ctx := context.Background() ctxWithCancel, cancelfunc := context.WithCancel(ctx) defer func() { //cancelfunc() time.Sleep(2 * time.Second) // 不等待的话子线程来不及打印，但是会退出 fmt.Println(\"end main\") // cancelfunc() }() go slowfunc(ctxWithCancel) time.Sleep(3 * time.Second) cancelfunc() } context.WithValue的使用 func valueFunc() { // 使用context.WithValue创建一个conext // 设置要通过context要传递的键值 ctx := context.WithValue(context.Background(), \"key\", \"value\") go valueFunc2(ctx) time.Sleep(time.Second) } func valueFunc2(ctx context.Context) { // 通过context提供的Value方法来获取数据 v := ctx.Value(\"key\") fmt.Println(\"value: \", v) } 参考 https://juejin.cn/post/7001273893780471845 ","date":"2023-05-22","objectID":"/go-context/:1:0","tags":["golang"],"title":"Golang 基本语法 —— 浅谈 Context","uri":"/go-context/"},{"categories":null,"content":"binlog、redo log、undo log","date":"2023-04-21","objectID":"/mysql-logs/","tags":["mysql"],"title":"MySQL 重要日志 —— binlog、redo log、undo log","uri":"/mysql-logs/"},{"categories":null,"content":" MySQL日志主要包括错误日志、查询日志、慢查询日志、回滚日志、重做日志、归档日志几大类。 本文主要聊一聊MySQL的重要日志，binlog 、redo log 、undo log ！ 该部分为作者梳理的精简内容，希望对您有帮助 ~ undo log（回滚日志） 是Innodb存储引擎层生成的日志，实现了事务的原子性，主要用于事务回滚和MVCC。 redo log（重做日志） redo log是是Innodb存储引擎层生成的日志，记录了某个数据页做了什么修改，比如对X表空间中的Y数据页Z偏移量的地方做了A更新，每当执行一个事务就会产生一条或多条物理日志。它实现了事务的持久性，主要用于掉电等故障恢复和提高MySQL写入性能(将写操作从随机写变成顺序写)。 binlog（归档日志） binlog是Server层生成的逻辑日志，记录内容是原始操作语句，主要用于数据备份和主从复制。 ","date":"2023-04-21","objectID":"/mysql-logs/:0:0","tags":["mysql"],"title":"MySQL 重要日志 —— binlog、redo log、undo log","uri":"/mysql-logs/"},{"categories":null,"content":"记录格式(可以通过 binlog-format 指定) statement：记录的是SQL语句(MySQL 5.7.7 之前) row：记录行的内容，一条更新前，一条更新后(MySQL 5.7.7 之后) mixed：混合模式，不推荐使用 ","date":"2023-04-21","objectID":"/mysql-logs/:1:0","tags":["mysql"],"title":"MySQL 重要日志 —— binlog、redo log、undo log","uri":"/mysql-logs/"},{"categories":null,"content":"主从复制怎么实现 MySQL的主从复制依赖于binlog，也就是记录MySQL上的所有变化并以二进制形式保存在磁盘上的日志。复制过程就是将binlog中的数据从主库传输到从库上。 ","date":"2023-04-21","objectID":"/mysql-logs/:2:0","tags":["mysql"],"title":"MySQL 重要日志 —— binlog、redo log、undo log","uri":"/mysql-logs/"},{"categories":null,"content":"具体过程 写入Binlog：主库写binlog日志，提交事务并更新本地存储数据。 同步Binlog：主库把binlog日志通过log dump 线程发送到所有从库，从库创建一个专门的I/O线程连接log dump线程接收主库的binlog日志，再把binlog信息写入relay log(中继日志)中，再返回给主库”复制成功”的响应。 回放Binlog：从库会创建一个用于回放binlog的线程，读取relay中继日志，然后回放binlog更新存储引擎中的数据，最终实现主从的数据一致性。 ","date":"2023-04-21","objectID":"/mysql-logs/:2:1","tags":["mysql"],"title":"MySQL 重要日志 —— binlog、redo log、undo log","uri":"/mysql-logs/"},{"categories":null,"content":"主从复制模型（三种） 同步复制：MySQL主库提交事务的线程要等待所有从库的复制响应，才返回客户端结果。 异步复制：MySQL主库提交事务的线程不会等待binlog同步到各从库，就返回客户端结果。 半同步复制：只要数据成功复制到任意一个从库上，主库的事务线程就可以返回客户端结果。 ","date":"2023-04-21","objectID":"/mysql-logs/:3:0","tags":["mysql"],"title":"MySQL 重要日志 —— binlog、redo log、undo log","uri":"/mysql-logs/"},{"categories":null,"content":"binlog刷盘机制 事务执行过程中，先把日志写入binlog cache(Server层的cache)； 事务提交的时候，在把binlog cache中的数据write到binlog文件（缓存中）； 至于binlog什么时候从缓存持久化到磁盘，这个由操作系统决定。 MySQL提供 sync_binlog 参数来控住数据库的binlog刷到磁盘上的频率： sync_binlog = 0 （fsync频率由操作系统决定） sync_binlog = 1 （每次提交事务后会fsync） sync_binlog = N（累积 N 个事务后才 fsync） 两阶段提交 ","date":"2023-04-21","objectID":"/mysql-logs/:4:0","tags":["mysql"],"title":"MySQL 重要日志 —— binlog、redo log、undo log","uri":"/mysql-logs/"},{"categories":null,"content":"什么是两阶段提交 ","date":"2023-04-21","objectID":"/mysql-logs/:5:0","tags":["mysql"],"title":"MySQL 重要日志 —— binlog、redo log、undo log","uri":"/mysql-logs/"},{"categories":null,"content":"为什么需要两阶段提交 如果只有 redo log 或者只有 binlog，那么事务就不需要两阶段提交。但是如果同时使用了 redo log 和 binlog，那么就需要保证这两种日志之间的一致性。否则，在数据库发生异常重启或者主从切换时，可能会出现主从库数据不一致的情况。 redo log ——\u003e 主库数据持久化 binlog ——\u003e 从库数据持久化 区别不同(binlog、redo log) 日志的提供者 : binlog 由 MySQL Server 提供，redo log 是 InnoDB 引擎特有。 日志的内容 : redo log 主要记录的是某个数据页做了什么修改，binlog 记录的是语句的原始逻辑，比如更新了某一行的某个字段。 使用的方式 : redo log 是循环写的，数据会被覆盖; binlog 是追加写，一个文件写满，就写下一个文件。 参考 https://www.xiaolincoding.com/mysql/log/how_update.html#binlog-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E5%88%B7%E7%9B%98 https://zhuanlan.zhihu.com/p/358573128 https://blog.csdn.net/weixin_63566550/article/details/129819638 ","date":"2023-04-21","objectID":"/mysql-logs/:6:0","tags":["mysql"],"title":"MySQL 重要日志 —— binlog、redo log、undo log","uri":"/mysql-logs/"},{"categories":null,"content":"struct可以比较吗","date":"2023-03-18","objectID":"/go-struct/","tags":["golang"],"title":"Golang 基本语法 —— struct可以比较吗","uri":"/go-struct/"},{"categories":null,"content":" struct能不能比较？得分情况！ struct能不能比较？ 很显然这句话包含了两种情况： 同一个struct的两个实例能不能比较？ 两个不同的struct的实例能不能比较？ 在分析上面两个问题前，先梳理一下golang中，哪些数据类型是可比较的，哪些是不可比较的： 可比较：Integer，Floating-point，String，Boolean，Complex(复数型)，Pointer，Channel，Interface，Array 不可比较：Slice，Map，Function 同一个struct 同一个struct的两个实例可比较也不可比较，当结构不包含不可直接比较成员变量时可直接比较，否则不可直接比较 type S struct { Name string Age int Address *int } func main() { a := S{ Name: \"aa\", Age: 1, Address: new(int), } b := S{ Name: \"aa\", Age: 1, Address: new(int), } fmt.Println(a == b) } 这段代码会输出false 因为上面的结构体不包含不可比较的成员变量，所以是可以比较的 type S struct { Name string Age int Address *int Data []int } func main() { a := S{ Name: \"aa\", Age: 1, Address: new(int), Data: []int{1, 2, 3}, } b := S{ Name: \"aa\", Age: 1, Address: new(int), Data: []int{1, 2, 3}, } fmt.Println(a == b) } 这段代码的输出是：./prog.go:28:14: invalid operation: a == b (struct containing []int cannot be compared) 因为结构体包含了不可比较的成员变量slice，导致代码编译不通过 reflect.DeepEqual 用来对含有不可直接比较的数据类型的结构体实例进行比较 type S struct { Name string Age int Address *int Data []int } func main() { a := S{ Name: \"aa\", Age: 1, Address: new(int), Data: []int{1, 2, 3}, } b := S{ Name: \"aa\", Age: 1, Address: new(int), Data: []int{1, 2, 3}, } fmt.Println(reflect.DeepEqual(a, b)) } 这段代码返回true DeepEqual函数用来判断两个值是否深度一致。具体比较规则如下： 不同类型的值永远不会深度相等 当两个数组的元素对应深度相等时，两个数组深度相等 当两个相同结构体的所有字段对应深度相等的时候，两个结构体深度相等 当两个函数都为nil时，两个函数深度相等，其他情况不相等（相同函数也不相等） 当两个interface的真实值深度相等时，两个interface深度相等 map的比较需要同时满足以下几个 两个map都为nil或者都不为nil，并且长度要相等 相同的map对象或者所有key要对应相同 map对应的value也要深度相等 指针，满足以下其一即是深度相等 两个指针满足go的==操作符 两个指针指向的值是深度相等的 切片，需要同时满足以下几点才是深度相等 两个切片都为nil或者都不为nil，并且长度要相等 两个切片底层数据指向的第一个位置要相同或者底层的元素要深度相等 注意：空的切片跟nil切片是不深度相等的 其他类型的值（numbers, bools, strings, channels）如果满足go的==操作符，则是深度相等的。要注意不是所有的值都深度相等于自己，例如函数，以及嵌套包含这些值的结构体，数组等 不同的struct 可以比较，也不可以比较，不含有不可比较类型的时候可以通过强转来比较。 type T2 struct { Name string Age int Arr [2]bool ptr *int } type T3 struct { Name string Age int Arr [2]bool ptr *int } func main() { var ss1 T2 var ss2 T3 // Cannot use 'ss2' (type T3) as type T2 in assignment //ss1 = ss2 // 不同结构体之间是不可以赋值的 ss3 := T2(ss2) fmt.Println(ss3==ss1) // true } 这段代码返回true 但是当结构体包含不可比较的成员变量时候，强转比较也会报错 type T2 struct { Name string Age int Arr [2]bool ptr *int map1 map[string]string } type T3 struct { Name string Age int Arr [2]bool ptr *int map1 map[string]string } func main() { var ss1 T2 var ss2 T3 ss3 := T2(ss2) fmt.Println(ss3==ss1) // 含有不可比较成员变量 } ./prog.go:28:14: invalid operation: ss3 == ss1 (struct containing map[string]string cannot be compared) 含有不能比较的结构体互转后可以使用deepequal比较 import ( \"fmt\" \"reflect\" ) type T2 struct { Name string Age int Arr [2]bool ptr *int map1 map[string]string } type T3 struct { Name string Age int Arr [2]bool ptr *int map1 map[string]string } func main() { var ss1 T2 var ss2 T3 ss3 := T2(ss2) fmt.Println(reflect.DeepEqual(ss3, ss1)) // 含有不可比较成员变量 } 这段代码返回true 问：struct可以作为map的key么 struct必须是可比较的，才能作为key，否则编译时报错 type T1 struct { Name string Age int Arr [2]bool ptr *int slice []int map1 map[string]string } type T2 struct { Name string Age int Arr [2]bool ptr *int } func main() { // n := make(map[T2]string, 0) // 无报错 // fmt.Print(n) // map[] m := make(map[T1]string, 0) fmt.Println(m) // invalid map key type T1 } 参考 https://www.jianshu.com/p/5641648664d8 ","date":"2023-03-18","objectID":"/go-struct/:0:0","tags":["golang"],"title":"Golang 基本语法 —— struct可以比较吗","uri":"/go-struct/"},{"categories":null,"content":"binlog、redo log、undo log","date":"2023-02-11","objectID":"/redis-expirationstrategymemoryobsolescence/","tags":["redis"],"title":"Redis 底层知识 —— 过期删除 \u0026 内存淘汰","uri":"/redis-expirationstrategymemoryobsolescence/"},{"categories":null,"content":" Redis重要的使用场景有两个 : 缓存和分布式锁。 这两个使用方式或多或少都涉及到两个底层知识 : 过期删除 \u0026 内存淘汰 过期删除策略 Redis 可以对 key 设置过期时间，因此需要相应的机制将已过期的键值对删除，而做这个工作的就是过期键值删除策略。 ","date":"2023-02-11","objectID":"/redis-expirationstrategymemoryobsolescence/:0:0","tags":["redis"],"title":"Redis 底层知识 —— 过期删除 \u0026 内存淘汰","uri":"/redis-expirationstrategymemoryobsolescence/"},{"categories":null,"content":"过期时间相关命令 # 设置过期时间 \u003e expire \u003ckey\u003e \u003cn\u003e \u003e pexpire \u003ckey\u003e \u003cn\u003e \u003e expireat \u003ckey\u003e \u003cn\u003e \u003e pexpireat \u003ckey\u003e \u003cn\u003e \u003e set \u003ckey\u003e \u003cvalue\u003e ex \u003cn\u003e \u003e set \u003ckey\u003e \u003cvalue\u003e px \u003cn\u003e \u003e setex \u003ckey\u003e \u003cn\u003e \u003cvalule\u003e # 查看 key 过期时间还剩多少 \u003e ttl \u003ckey\u003e # 取消 key 的过期时间 \u003e persist key (integer) 1 ","date":"2023-02-11","objectID":"/redis-expirationstrategymemoryobsolescence/:1:0","tags":["redis"],"title":"Redis 底层知识 —— 过期删除 \u0026 内存淘汰","uri":"/redis-expirationstrategymemoryobsolescence/"},{"categories":null,"content":"Redis 如何判定 key 已过期了？ 每当我们对一个 key 设置了过期时间时，Redis 会把该 key 带上过期时间存储到一个过期字典（expires dict）中，也就是说「过期字典」保存了数据库中所有 key 的过期时间。 Redis判定过期是通过将当前时间与过期时间进行比较来进行的。 ","date":"2023-02-11","objectID":"/redis-expirationstrategymemoryobsolescence/:2:0","tags":["redis"],"title":"Redis 底层知识 —— 过期删除 \u0026 内存淘汰","uri":"/redis-expirationstrategymemoryobsolescence/"},{"categories":null,"content":"Redis 过期删除策略 Redis 选择「惰性删除+定期删除」这两种策略配和使用. ","date":"2023-02-11","objectID":"/redis-expirationstrategymemoryobsolescence/:3:0","tags":["redis"],"title":"Redis 底层知识 —— 过期删除 \u0026 内存淘汰","uri":"/redis-expirationstrategymemoryobsolescence/"},{"categories":null,"content":"常见的过期删除策略 定时删除 : 在设置 key 的过期时间时，同时创建一个定时事件，当时间到达时，由事件处理器自动执行 key 的删除操作。 惰性删除 : 不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。 定期删除 : 每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。 内存淘汰策略 ","date":"2023-02-11","objectID":"/redis-expirationstrategymemoryobsolescence/:3:1","tags":["redis"],"title":"Redis 底层知识 —— 过期删除 \u0026 内存淘汰","uri":"/redis-expirationstrategymemoryobsolescence/"},{"categories":null,"content":"设置 Redis 最大运行内存 在配置文件 redis.conf 中，可以通过参数 maxmemory 来设定最大运行内存 ","date":"2023-02-11","objectID":"/redis-expirationstrategymemoryobsolescence/:4:0","tags":["redis"],"title":"Redis 底层知识 —— 过期删除 \u0026 内存淘汰","uri":"/redis-expirationstrategymemoryobsolescence/"},{"categories":null,"content":"Redis 内存淘汰策略（8种） ","date":"2023-02-11","objectID":"/redis-expirationstrategymemoryobsolescence/:5:0","tags":["redis"],"title":"Redis 底层知识 —— 过期删除 \u0026 内存淘汰","uri":"/redis-expirationstrategymemoryobsolescence/"},{"categories":null,"content":"不进行数据淘汰的策略 noeviction（Redis3.0之后，默认的内存淘汰策略）: 它表示当运行内存超过最大设置内存时，不淘汰任何数据，这时如果有新的数据写入，会报错通知禁止写入，不淘汰任何数据，单纯的查询或者删除操作可以正常工作。 ","date":"2023-02-11","objectID":"/redis-expirationstrategymemoryobsolescence/:5:1","tags":["redis"],"title":"Redis 底层知识 —— 过期删除 \u0026 内存淘汰","uri":"/redis-expirationstrategymemoryobsolescence/"},{"categories":null,"content":"进行数据淘汰的策略 过期时间的数据中进行淘汰 volatile-random：随机淘汰设置了过期时间的任意键值； volatile-lru（Redis3.0 之前，默认的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最久未使用的键值； volatile-lfu（Redis 4.0 后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最少使用的键值； volatile-ttl：优先淘汰更早过期的键值。 所有数据中进行淘汰 allkeys-random：随机淘汰任意键值; allkeys-lru：淘汰整个键值中最久未使用的键值； allkeys-lfu（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值。 ","date":"2023-02-11","objectID":"/redis-expirationstrategymemoryobsolescence/:5:2","tags":["redis"],"title":"Redis 底层知识 —— 过期删除 \u0026 内存淘汰","uri":"/redis-expirationstrategymemoryobsolescence/"},{"categories":null,"content":"如何查看当前 Redis 使用的内存淘汰策略 127.0.0.1:6379\u003e config get maxmemory-policy 1) \"maxmemory-policy\" 2) \"noeviction\" 参考 https://www.xiaolincoding.com/redis/module/strategy.html#%E8%BF%87%E6%9C%9F%E5%88%A0%E9%99%A4%E7%AD%96%E7%95%A5 ","date":"2023-02-11","objectID":"/redis-expirationstrategymemoryobsolescence/:5:3","tags":["redis"],"title":"Redis 底层知识 —— 过期删除 \u0026 内存淘汰","uri":"/redis-expirationstrategymemoryobsolescence/"},{"categories":null,"content":"make和new是内置函数，不是关键字，var是关键字","date":"2023-01-21","objectID":"/go-diff_of_stringbyte/","tags":["golang"],"title":"Golang 基本语法 —— []byte和string的不同","uri":"/go-diff_of_stringbyte/"},{"categories":null,"content":" []byte和string的不同 为啥string和[]byte类型转换需要一定的代价？ 为啥内置函数copy会有一种特殊情况copy(dst []byte, src string) int? string和[]byte，底层都是数组，但为什么[]byte比string灵活，拼接性能也更高（动态字符串拼接性能对比）? 何为string？ 什么是字符串？标准库builtin的解释： type string string is the set of all strings of 8-bit bytes, conventionally but not necessarily representing UTF-8-encoded text. A string may be empty, but not nil. Values of string type are immutable. 简单的来说字符串是一系列8位字节的集合，通常但不一定代表UTF-8编码的文本。字符串可以为空，但不能为nil。而且字符串的值是不能改变的。不同的语言字符串有不同的实现，在go的源码中src/runtime/string.go，string的定义如下： type stringStruct struct { str unsafe.Pointer len int } 可以看到str其实是个指针，指向某个数组的首地址，另一个字段是len长度。那到这个数组是什么呢？ 在实例化这个stringStruct的时候： func gostringnocopy(str *byte) string { ss := stringStruct{str: unsafe.Pointer(str), len: findnull(str)} s := *(*string)(unsafe.Pointer(\u0026ss)) return s } 哈哈，其实就是byte数组，而且要注意string其实就是个struct。 何为[]byte? 首先在go里面，byte是uint8的别名。而slice结构在go的源码中src/runtime/slice.go定义： type slice struct { array unsafe.Pointer len int cap int } array是数组的指针，len表示长度，cap表示容量。除了cap，其他看起来和string的结构很像。 但其实他们差别真的很大。 区别 字符串的值是不能改变 在前面说到了字符串的值是不能改变的，这句话其实不完整，应该说字符串的值不能被更改，但可以被替换。 还是以string的结构体来解释吧，所有的string在底层都是这样的一个结构体stringStruct{str: str_point, len: str_len}，string结构体的str指针指向的是一个字符常量的地址， 这个地址里面的内容是不可以被改变的，因为它是只读的，但是这个指针可以指向不同的地址，我们来对比一下string、[]byte类型重新赋值的区别： s := “A1” // 分配存储\"A1\"的内存空间，s结构体里的str指针指向这快内存 s = “A2” // 重新给\"A2\"的分配内存空间，s结构体里的str指针指向这快内存 其实[]byte和string的差别是更改变量的时候array的内容可以被更改。 s := []byte{1} // 分配存储1数组的内存空间，s结构体的array指针指向这个数组。 s = []byte{2} // 将array的内容改为2 因为string的指针指向的内容是不可以更改的，所以每更改一次字符串，就得重新分配一次内存，之前分配空间的还得由gc回收，这是导致string操作低效的根本原因。 string和[]byte的相互转换 将string转为[]byte，语法[]byte(string)源码如下： func stringtoslicebyte(buf *tmpBuf, s string) []byte { var b []byte if buf != nil \u0026\u0026 len(s) \u003c= len(buf) { *buf = tmpBuf{} b = buf[:len(s)] } else { b = rawbyteslice(len(s)) } copy(b, s) return b } func rawstring(size int) (s string, b []byte) { p := mallocgc(uintptr(size), nil, false) stringStructOf(\u0026s).str = p stringStructOf(\u0026s).len = size *(*slice)(unsafe.Pointer(\u0026b)) = slice{p, size, size} return } 可以看到b是新分配的，然后再将s复制给b，至于为啥copy函数可以直接把string复制给[]byte，那是因为go源码单独实现了一个slicestringcopy函数来实现，具体可以看src/runtime/slice.go。 将[]byte转为string，语法string([]byte)源码如下： func slicebytetostring(buf *tmpBuf, b []byte) string { l := len(b) if l == 0 { // Turns out to be a relatively common case. // Consider that you want to parse out data between parens in \"foo()bar\", // you find the indices and convert the subslice to string. return \"\" } if raceenabled \u0026\u0026 l \u003e 0 { racereadrangepc(unsafe.Pointer(\u0026b[0]), uintptr(l), getcallerpc(unsafe.Pointer(\u0026buf)), funcPC(slicebytetostring)) } if msanenabled \u0026\u0026 l \u003e 0 { msanread(unsafe.Pointer(\u0026b[0]), uintptr(l)) } s, c := rawstringtmp(buf, l) copy(c, b) return s } func rawstringtmp(buf *tmpBuf, l int) (s string, b []byte) { if buf != nil \u0026\u0026 l \u003c= len(buf) { b = buf[:l] s = slicebytetostringtmp(b) } else { s, b = rawstring(l) } return } 依然可以看到s是新分配的，然后再将b复制给s。 正因为string和[]byte相互转换都会有新的内存分配，才导致其代价不小，但读者千万不要误会，对于现在的机器来说这些代价其实不值一提。 但如果想要频繁string和[]byte相互转换（仅假设），又不会有新的内存分配，能有办法吗？答案是有的。 package string_slicebyte_test import ( \"log\" \"reflect\" \"testing\" \"unsafe\" ) func stringtoslicebyte(s string) []byte { sh := (*reflect.StringHeader)(unsafe.Pointer(\u0026s)) bh := reflect.SliceHeader{ Data: sh.Data, Len: sh.Len, Cap: sh.Len, } return *(*[]byte)(unsafe.Pointer(\u0026bh)) } func slicebytetostring(b []byte) string { bh := (*reflect.SliceHeader)(unsafe.Pointer(\u0026b)) sh := reflect.StringHeader{ Data: bh.Data, Len: bh.Len, } return *(*string)(unsafe.Pointer(\u0026sh)) } func TestStringSliceByte(t *testing.T) { s1 := \"abc\" b1 := []byte(\"def\") copy(b1, s1) log.Println(s1, b1) s := \"hello\" b2 := stringtoslicebyte(s) log.Println(b2) // b2[0] = byte(99) unexpected fault address b3 := []byte(\"test\") s3 := slicebytetostring(b3) log.Println(s3) } 答案虽然有，但强烈推荐不要使用这种方法来转换类型，因为如果通过stringtoslicebyte将string转为[]byte的时候，共用的时同一块内存，原先的string内存区域是只读的，一但更改将会导致整个进程down掉，而且这个错误是runtime没法恢复的。 如何取舍？ 既然string就是一系列字节，而[]byte也可以表达一系列字节，那么实际运用中应当如何取舍？ string可以直接比较，而[]by","date":"2023-01-21","objectID":"/go-diff_of_stringbyte/:0:0","tags":["golang"],"title":"Golang 基本语法 —— []byte和string的不同","uri":"/go-diff_of_stringbyte/"},{"categories":null,"content":"锁机制","date":"2023-01-02","objectID":"/go-sync_locking_mechanism/","tags":["golang"],"title":"Golang 并发编程 —— 锁机制","uri":"/go-sync_locking_mechanism/"},{"categories":null,"content":" 在日常生活中，锁是为了保护一些东西，比如门锁、密码箱锁，可以理解对资源的保护。 在编程世界里，锁也是为了保护资源，比如文件锁 : 同一时间只也许一个用户修改文件。 本文就梳理了一下 Golang 中 sync 包中的锁机制。希望对您有帮助 ~ ","date":"2023-01-02","objectID":"/go-sync_locking_mechanism/:0:0","tags":["golang"],"title":"Golang 并发编程 —— 锁机制","uri":"/go-sync_locking_mechanism/"},{"categories":null,"content":"sync.Mutex(互斥锁) 这是一个标准的互斥锁，平时用的也比较多，用法也非常简单，lock用于加锁，unlock用于解锁，配合defer使用，完美。 ","date":"2023-01-02","objectID":"/go-sync_locking_mechanism/:1:0","tags":["golang"],"title":"Golang 并发编程 —— 锁机制","uri":"/go-sync_locking_mechanism/"},{"categories":null,"content":"sync.RWMutex(读写锁) 读写锁是互斥锁的升级版，它最大的优点就是支持多读，但是读和写、以及写与写之间还是互斥的，所以比较适合读多写少的场景。 ","date":"2023-01-02","objectID":"/go-sync_locking_mechanism/:2:0","tags":["golang"],"title":"Golang 并发编程 —— 锁机制","uri":"/go-sync_locking_mechanism/"},{"categories":null,"content":"参考 https://wangbjun.site/2020/coding/golang/locker.html ","date":"2023-01-02","objectID":"/go-sync_locking_mechanism/:3:0","tags":["golang"],"title":"Golang 并发编程 —— 锁机制","uri":"/go-sync_locking_mechanism/"},{"categories":null,"content":"make和new是内置函数，不是关键字，var是关键字","date":"2022-12-17","objectID":"/go-diff_of_newmake/","tags":["golang"],"title":"Golang 基本语法 —— var、new、make区别及使用","uri":"/go-diff_of_newmake/"},{"categories":null,"content":" make和new是内置函数，不是关键字，var是关键字。 make 只能用来分配及初始化类型为 slice、map、chan 的数据，而 new 可以分配任意类型的数据。 new 分配返回的是指针，即类型 *Type。make 返回引用，即 Type。 new 分配的空间被清零。make 分配空间后，会进行初始化。 一：对于值类型的变量，我们通过var 声明(包括结构体)，系统会默认为他分配内存空间，并赋该类型的零值。如下，我们声明一个int类型变量i，输出为0。 var i int fmt.Println(i) //i=0 而如果我们声明一个指针类型的变量，系统不会为他分配内存(应该是不会为这个指针分配一个内存给他指向)，默认就是nil。此时如果你想直接使用，那么系统会抛异常。 var j *int fmt.Println(j) //nil类型，因为指针的0值就是nil fmt.Println(\u0026j) //0xc00000e028 这是指针变量的地址 fmt.Println(*j) //因为这个指针没有指向任何内存,报错 *j = 10 //invalid memory address or nil pointer dereference， 空指针还没指向任何内存，是不能使用的。 二：那么要想使用，此时就需要new出场啦。 var j *int j = new(int) // j里面的内容指向一块分配好的内存地址，地址里面设置int的零值：0 fmt.Println(j) // 0xc000018040 fmt.Println(*j) //0 *j = 10 fmt.Println(*j) 声明指针类型变量后，通过new为他分配指向的内存，有了内存空间，这个变量就可以自由的使用了。 来看一下new函数的签名： 它只接受一个参数，这个参数是一个类型，**分配好内存后，返回一个指向该类型内存地址的指针。这块内存上存的是类型的零值。**这个类型也能是指针。 package main import ( \"fmt\" ) func main(){ a := new(*int) fmt.Println(a) fmt.Println(*a) *a = new(int) fmt.Println(*a) fmt.Println(**a) } 0xc0000b2018 \u003cnil\u003e 0xc0000b8010 0 *但是，**实际在工程使用中，通常是直接声明指针使用，不需要new操作。 三：make和new不同，make用于map, slice,chan 的内存创建，因为他们三个是引用类型，直接返回这三个类型本身。make签名是： func make(t Type, size ...IntegerType) Type make 是分配内存并初始化，初始化并不是置为零值。 与new一样，它的第一个参数也是一个类型，但是不一样的是，make返回的是传入的类型，而不是指针！ var c chan int //声明管道类型变量c，此时c还是nil，不可用； fmt.Printf(\"%#v \\\\n\",c) //(chan int)(nil) c = make(chan int) fmt.Printf(\"%#v\", c) //(chan int)(0xc000062060) 声明管道类型变量c，此时c还是nil，不可用； 通过make来分配内存并初始化，c就获得了内存可以使用了。 所以，我们在使用map, slice,chan 的时候，需要先对他们用make初始化，然后在进行操作。 总结： var 分配内存，赋0值，返回类型 new 分配内存，赋0值，返回类型指针（指向刚才分配内存的指针） make给map，channel，slice分配内存，不赋0值，返回类型 Var指针类型一般是var+new；Var三种引用类型时候，一般是var+make make和new的区别 new 和 make都是用来创建和分配内存的，可能在栈上，也可能在堆上，是内存逃逸分析后确定创建在哪里的。 new 返回的是指针，指向新分配的类型的零值；make 返回的是值，这个值已经被初始化（例如，一个新的切片，它的元素已经被分配了内存）。 new 可以用于任何类型，而 make 只能用于切片、映射和通道。 make 创建的切片、映射或通道已经准备好使用，而 new 创建的值需要进一步初始化。 为什么要给三种引用类型单独实现一个make 函数？ 这是因为slice, map和chan的底层结构上要求在使用slice，map和chan的时候必须初始化，如果不初始化，那slice，map和chan的值就是零值，也就是nil。我们知道： map如果是nil，是不能往map插入元素的，插入元素会引发panic chan如果是nil，往chan发送数据或者从chan接收数据都会阻塞 slice会有点特殊，理论上slice如果是nil，也是没法用的。但是append函数处理了nil slice的情况，可以调用append函数对nil slice做扩容。但是我们使用slice，总是会希望可以自定义长度或者容量，这个时候就需要用到make。 那么，可以使用new来初始化引用类型吗？可以的！ 参考 https://huweicai.com/ https://draveness.me/golang/docs/part2-foundation/ch05-keyword/golang-make-and-new/ https://blog.wu-boy.com/2021/06/what-is-different-between-new-and-make-in-golang/ https://fivezh.github.io/2020/03/15/golang-new-make/ https://zhuanlan.zhihu.com/p/486998884 http://www.codingbygolang.com/make-or-new/#%E5%87%BD%E6%95%B0-new-%E7%AD%BE%E5%90%8D ","date":"2022-12-17","objectID":"/go-diff_of_newmake/:0:0","tags":["golang"],"title":"Golang 基本语法 —— var、new、make区别及使用","uri":"/go-diff_of_newmake/"},{"categories":null,"content":" 博客的意义在于自己梳理知识，总结经验，顺便和他人进行技术交流。 这是我的第一篇博客，记录我是如何搭建这个网站的！希望对您也有帮助~ ","date":"2022-11-06","objectID":"/blog-setup/:0:0","tags":["blog"],"title":"Blog 搭建之路","uri":"/blog-setup/"},{"categories":null,"content":"所需工具 ","date":"2022-11-06","objectID":"/blog-setup/:1:0","tags":["blog"],"title":"Blog 搭建之路","uri":"/blog-setup/"},{"categories":null,"content":"Hugo + GitHub Pages + GitHub Actions + DomainRegistration ","date":"2022-11-06","objectID":"/blog-setup/:1:1","tags":["blog"],"title":"Blog 搭建之路","uri":"/blog-setup/"},{"categories":null,"content":"1 概念 ","date":"2022-11-06","objectID":"/blog-setup/:2:0","tags":["blog"],"title":"Blog 搭建之路","uri":"/blog-setup/"},{"categories":null,"content":"1.1 什么是 Hugo？ Hugo 是用 Go 语言写的静态网站生成器（Static Site Generator）。可以把 Markdown 文件转化成 HTML 文件。 ","date":"2022-11-06","objectID":"/blog-setup/:2:1","tags":["blog"],"title":"Blog 搭建之路","uri":"/blog-setup/"},{"categories":null,"content":"1.2 什么是 GitHub Pages？ GitHub Pages 是一组静态网页集合（Static Web Page），这些静态网页 HTML 文件由 GitHub 托管（host）和发布，所以是 GitHub + Pages。 ","date":"2022-11-06","objectID":"/blog-setup/:2:2","tags":["blog"],"title":"Blog 搭建之路","uri":"/blog-setup/"},{"categories":null,"content":"1.3 Github Action Hugo 都是静态博客，即最终生成的是静态页面，而所谓部署就是把这些静态文件放到 web 服务器(比如 Nginx、Caddy) 的对应目录就行了。 因此整个 Github Action 只需要做两件事： 1）编译，生成静态文件 2）部署，把静态文件移动到合适的位置 - 比如放到某个云服务器上 - 或者放到 Github Pages 然后我们再通过 git push 来触发 Github Action 就可以了。 ","date":"2022-11-06","objectID":"/blog-setup/:2:3","tags":["blog"],"title":"Blog 搭建之路","uri":"/blog-setup/"},{"categories":null,"content":"2 过程 ","date":"2022-11-06","objectID":"/blog-setup/:3:0","tags":["blog"],"title":"Blog 搭建之路","uri":"/blog-setup/"},{"categories":null,"content":"2.1 配置Hugo 2.1.1 安装Hugo 这里使用包管理器安装 Hugo，我的操作系统是 Mac OS，所以使用 Homebrew 安装 Hugo。如果你使用的是 Windows 或 Linux，可以根据 Hugo 文档提示的方式安装： Hugo 文档：Install Hugo brew install hugo # 查看 Hugo 是否安装成功，显示 Hugo 版本号代表 Hugo 安装成功。 hugo version 2.1.2 创建 Hugo 网站 通过上述命令安装 hugo 程序后，就可以通过 hugo new site 命令进行网站创建、配置与本地调试了。 hugo new site Blog 2.1.3 配置主题 当通过上文命令创建我们的站点后，需要进行主题配置，Hugo 社区有了很丰富的主题，可以通过官网 Themes 菜单选择自己喜欢的风格，查看预览效果，选择后可以进入主题项目仓库，一般都会有很详细的安装及配置说明。下面我就以我目前在使用的 LoveIt 这个主题为例，演示一下配置流程。 我们可以将主题仓库直接 git clone 下来进行使用，但这种方式有一些弊端，当之后自己对主题进行修改后，可能会与原主题产生一些冲突，不方便版本管理与后续更新。我采用的是将原主题仓库 fork 到自己的账户，并使用 git submodule 方式进行仓库链接，这样后续可以对主题的修改进行单独维护。 cd blog-test/ git init git submodule add https://github.com/pseudoyu/LoveIt themes/LoveIt 每个主题一般都会提供一些实例配置与初始页面，开始使用主题时可以将其 exampleSite/ 目录下的文件复制到站点目录下，在此基础上进行调整配置。 cp -rf themes/LoveIt/exampleSite/* ./ 初始化主题基础配置后，我们可以在 config.toml 文件中进行站点细节配置，具体配置项参考各主题说明文档。 2.1.4 发布文章 完成后，可以通过 hugo new 命令发布新文章。 hugo new posts/blog-test.md 2.1.5 本地调试 Hugo 会生成静态网页，我们在本地编辑调试时可以通过 hugo server 命令进行本地实时调试预览，无须每次都重新生成。 hugo server 运行服务后，我们可以通过浏览器 http://localhost:1313 地址访问我们的本地预览网页。 ","date":"2022-11-06","objectID":"/blog-setup/:3:1","tags":["blog"],"title":"Blog 搭建之路","uri":"/blog-setup/"},{"categories":null,"content":"2.2 创建GitHub仓库 命名博客源仓库（username.github.io） 勾选 Public，设置为公开仓库。 勾选添加 README 文件 ","date":"2022-11-06","objectID":"/blog-setup/:3:2","tags":["blog"],"title":"Blog 搭建之路","uri":"/blog-setup/"},{"categories":null,"content":"2.3 创建GitHub Page 在博客源仓库下创建GitHub Pages（Settings-\u003ePages） ","date":"2022-11-06","objectID":"/blog-setup/:3:3","tags":["blog"],"title":"Blog 搭建之路","uri":"/blog-setup/"},{"categories":null,"content":"2.4 创建GitHub Actions 需要在仓库根目录下创建 .github/workflows 这个二级目录，然后在 workflows 下以 .yml 形式配置 Github Action。 name:publish to gh-pages# 流水线名称on:# on 表示 GitHub Action 触发条件push:branches:- main# main分支env:REGISTRY:ghcr.ioIMAGE_NAME:${{ github.repository }}jobs:# jobs 表示 GitHub Action 中的任务build:runs-on:ubuntu-latest# runs-on 表示 GitHub Action 运行环境，我们选择了 ubuntu-latest。# permissions:# contents: read# packages: writeconcurrency:group:${{ github.workflow }}-${{ github.ref }}steps:- name:checkout# 检查uses:actions/checkout@v2# uses 中的为 GitHub Action 中的一个插件with:submodules:true# Fetch Hugo themes (true OR recursive)fetch-depth:0# Fetch all history for .GitInfo and .Lastmod- name:setup hugo# 安装uses:peaceiris/actions-hugo@v2 with:hugo-version:'0.105.0'# hugo的版本号extended:true- name:build web# 构建run:hugo --minify- name:deploy web# 部署uses:peaceiris/actions-gh-pages@v3if:${{ github.ref == 'refs/heads/main' }}with:github_token:${{ secrets.GH_PAGE_ACTION_TOKEN }}publish_dir:./publiccname:mazikai002.cn# 重点 ！！！个人域名使用# PUBLISH_BRANCH: gh-pages，peaceiris/actions-gh-pages@v3插件默认指定生成分支 整个 Action 一个包含 4 个步骤： 1）拉取代码 2）准备 hugo 环境 3）使用 hugo 编译生成静态文件 4）把生成的静态文件发布到 Github Pages 以上需要特别注意的是 Hugo 的版本以及是否启用 hugo 扩展。 因为我们需要从仓库的main分支推送到仓库的gh-pages分支，这需要特定权限，故要在 GitHub 账户下 Setting - Developer setting - Personal access tokens 下创建一个 Token。 权限需要开启admin:org(read write)、repo、workflow三块权限。 配置后复制生成的 Token（注：只会出现一次），然后在我们博客源仓库的 Settings - Secrets and variables - Actions - Environment secrets 中添加 GITHUB_TOKEN 环境变量为刚才的 Token，这样 GitHub Action 就可以获取到 Token 了。 同时 Settings - Actions - General的最下方的一个选项选择Read and write permissions 完成上述配置后，推送代码至仓库，即可触发 GitHub Action，自动生成博客页面并推送至 GitHub Pages 仓库。 ","date":"2022-11-06","objectID":"/blog-setup/:3:4","tags":["blog"],"title":"Blog 搭建之路","uri":"/blog-setup/"},{"categories":null,"content":"2.5 博客绑定域名 2.5.1 创建 CNAME 首先在你的库下面添加一个 CNAME （别名记录）文件，建议直接在 GitHub 那创建!(这一步在workflows的yml文件中最后一行已经配置)，参考你的域名进行编写。 2.5.2 添加 DNS 解析 然后是添加解析，我域名是在腾讯云买的，所以直接在腾讯云那添加解析了。 我添加的解析如下,供参考，记得把 username 改成你自己的。 @ A 185.199.109.153 @ A 185.199.110.153 www CNAME username.github.io. A 记录的 ip 地址可以在下面中选择 185.199.108.153 185.199.109.153 185.199.110.153 185.199.111.153 2.5.3 修改设置 添加完成后进入库的设置，找到 GitHub Pages ，如果能看到类似 Your site is published at https://mazikai002.cn/ 这样的文字，说明就搞定了。 Enforce HTTPS 最好勾选上，GitHub 提供的这个可以直接让你的网站从 HTTP 升级到 HTTPS，非常赞。 ","date":"2022-11-06","objectID":"/blog-setup/:3:5","tags":["blog"],"title":"Blog 搭建之路","uri":"/blog-setup/"},{"categories":null,"content":"3 流程 使用hugo创建个人站点，hugo new site，hugo new post… git commit 提交 触发 github action .github/workflows/my-pipeline.yml 并满足设置中的 on 条件 触发 pipeline 中的 steps checkout：相当与 git clone，并且后续操作具有 github 完整权限，可以通过 permissions 设置 setup hugo：准备构建要求，安装对应版本，注意是否需要 extended build：构建出静态文件，并输出到 public 文件夹 deploy：该插件来自 插件市场 自动创建分支 gh-pages 自动 copy public 到新分支 自动提交 自动生成 CNAME 文件，根据 cname 设置，想要 自定义域名 的注意这里了 打开 https://github.com/{你的名字}/{你的仓库}/settings/pages（后续步骤只需要一次） Source 选择 gh-pages ，文件夹: 默认 / (root) ，并 save 注意上方提示 Your site is ready to be published at https://xxx.github.io/xxx/ 将域名部分做 解析 Custom domain 设置 自己的域名 Enforce HTTPS 点一下，然后等一会 ","date":"2022-11-06","objectID":"/blog-setup/:4:0","tags":["blog"],"title":"Blog 搭建之路","uri":"/blog-setup/"},{"categories":null,"content":"4 总结 可以将主题下相关文件复制到 blog 网站根目录下，因为这样可以直接渲染网站效果，而又不影响主题本身的内容。 主要是 themes\\LoveIt\\exampleSite 目录下文件。 发布文章如果有参数 draft ，记得将值设为 false，或者删除 draft，不然会被认定为草稿只能本地运行而不能运行到网站上。 Hogo方式搭建博客基本就是安装，建站，下载主题，配置主题参数，编写几大内容。 使用 GitHub Pages + GitHub Actions 方式部署博客可以节省传统的构建部署繁琐步骤，简化搭建博客的过程，让个人博客爱好者更能专注于自身博客的内部撰写，而不用拘泥于博客整体的维护过程，提高效率 ","date":"2022-11-06","objectID":"/blog-setup/:5:0","tags":["blog"],"title":"Blog 搭建之路","uri":"/blog-setup/"},{"categories":null,"content":"5. 参考 https://huweicai.com/ https://www.pseudoyu.com/zh/2022/05/29/deploy_your_blog_using_hugo_and_github_action/ https://cuttontail.blog/blog/create-a-wesite-using-github-pages-and-hugo/ https://blog.csdn.net/wolanx/article/details/122857729?spm=1001.2014.3001.5502 https://cloud.tencent.com/developer/article/1421879 https://h1z3y3.me/posts/hugo-auto-deploy-github-with-actions/ ","date":"2022-11-06","objectID":"/blog-setup/:6:0","tags":["blog"],"title":"Blog 搭建之路","uri":"/blog-setup/"},{"categories":null,"content":"Mazikai","date":"2021-09-02","objectID":"/about/","tags":null,"title":"","uri":"/about/"},{"categories":null,"content":" ~ Not Day But Today ~ 2020年拍摄于宜昌拍摄于宜昌 \" 2020年拍摄于宜昌 ","date":"2021-09-02","objectID":"/about/:0:0","tags":null,"title":"","uri":"/about/"},{"categories":null,"content":"个人简介 Hi , Buddy . My name is Mazikai . Major in DevOps \u0026 Observability . If you have any questions or idea, Communications are welcome! Please Mail ","date":"2021-09-02","objectID":"/about/:1:0","tags":null,"title":"","uri":"/about/"},{"categories":null,"content":"个人经历 贝壳找房科技有限公司 基础后端开发 2021.07~至今 华中科技大学.硕士 材料加工工程 2018.07~2021.06 武汉科技大学.学士 材料成型及控制工程 2014.07~2018.06 ","date":"2021-09-02","objectID":"/about/:2:0","tags":null,"title":"","uri":"/about/"},{"categories":null,"content":"专业技能 计算机基础 : 掌握操作系统、计算机网络、数据结构与算法；了解计算机组成原理 编程语言 : 掌握 Go 语言(调度模型、内存管理、并发编程)、Shell 脚本；了解 Java 语言 语言框架 : 掌握 Gin 、GORM 等主流框架 数据库 : 掌握 MySQL 数据库及常见优化手段(索引、SQL 优化、读写分离、分库分表)、Redis 数据库(缓存、分布式锁) 分布式 : 掌握 Prometheus 指标监控、Consul 服务网络；了解 SkyWalking 链路追踪、Kafka 消息队列、Elasticsearch 搜索引擎、ELK 日志检索、OpenTelemetry 可观测性框架 云原生 : 了解 Kubernetes 容器编排平台、APISIX 云原生网关 其他 : 掌握 Linux 及常用命令(有开发部署项目经验)、 Git、Docker、Markdown ","date":"2021-09-02","objectID":"/about/:3:0","tags":null,"title":"","uri":"/about/"}]